{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보충 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_linear_regression.ipynb의 주요 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv('data/bikeshare.csv')\n",
    "\n",
    "# Year와 Month를 추출\n",
    "datetime = pd.DatetimeIndex(data['datetime'])\n",
    "data['year'] = datetime.year\n",
    "data['month'] = datetime.month\n",
    "data['hour'] = datetime.hour\n",
    "\n",
    "# \"count\" is a method, so it's best to name that column something else\n",
    "data.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Handling 'season' variable\n",
    "season_dummies = pd.get_dummies(data.season, prefix='season')\n",
    "season_dummies.drop(season_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, season_dummies], axis=1)\n",
    "\n",
    "# Add derivative variable \"daytime\"\n",
    "data['daytime'] = ((data.hour > 6) & (data.hour < 21)).astype(int)\n",
    "\n",
    "# Handling 'hour' variable\n",
    "hour_dummies = pd.get_dummies(data.hour, prefix='hour')\n",
    "hour_dummies.drop(hour_dummies.columns[0], axis=1, inplace=True)\n",
    "data = pd.concat([data, hour_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형회귀모델을 학습하는 함수를 조금 수정하였습니다.\n",
    "다음을 포함하는 dictionary를 출력하는 함수로 변경하였습니다.\n",
    "- 각 변수에 대응하는 계수들(coefficients)과 intercept\n",
    "- Train set에서의 RMSE, R^2\n",
    "- Test set에서의 RMSE, R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that accepts a list of features and\n",
    "# returns coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "def train_test_linreg(d, feature_cols):\n",
    "    X = d[feature_cols]\n",
    "    Y = d.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = feature_cols)\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour에 대한 binary dummy variable만 이용하여 선형회귀모델을 학습\n",
    "hour_cols = list(data.columns[data.columns.str.startswith('hour_')])\n",
    "result = train_test_linreg(data, hour_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': hour_1     -22.580917\n",
       " hour_2     -32.757474\n",
       " hour_3     -44.209704\n",
       " hour_4     -49.961957\n",
       " hour_5     -36.711049\n",
       " hour_6      16.801172\n",
       " hour_7     159.656510\n",
       " hour_8     309.943473\n",
       " hour_9     160.149618\n",
       " hour_10    121.193570\n",
       " hour_11    147.090587\n",
       " hour_12    202.425259\n",
       " hour_13    200.110370\n",
       " hour_14    195.261156\n",
       " hour_15    195.486156\n",
       " hour_16    266.890255\n",
       " hour_17    419.952457\n",
       " hour_18    379.068371\n",
       " hour_19    264.786324\n",
       " hour_20    173.622659\n",
       " hour_21    125.548656\n",
       " hour_22     77.631922\n",
       " hour_23     34.730308\n",
       " dtype: float64,\n",
       " 'intercept': 56.263843648208365,\n",
       " 'rmse_test': 128.47511657303031,\n",
       " 'rmse_train': 124.92842235488433,\n",
       " 'rsquared_test': 0.49192464950577075,\n",
       " 'rsquared_train': 0.52631453386835414}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check coefficients, intercept, training RMSE/R^2 and testing RMSE/R^2\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression & Lasso regression\n",
    "### 두 모델의 공통점\n",
    "- **Regularization**: 모델 계수가 커지는 것에 대한 penalty를 부여함으로써 모델의 overfitting(과적합)을 방지\n",
    "- 기본적인 multiple linear regression (다중선형회귀분석) 은 변수 간의 [다중공산성(multicollinearity)](https://ko.wikipedia.org/wiki/%EB%8B%A4%EC%A4%91%EA%B3%B5%EC%84%A0%EC%84%B1)에 의해 성능이 하락하는데, 이 두 회귀모델은 이에 대해 대처할 수 있는 모델\n",
    "- 모델의 parameter(모수)가 존재: 계수 크기에 대한 penalty를 얼마나 줄 것인가 (**alpha**)\n",
    "- alpha가 0이면 단순 다중선형회귀모델과 일치\n",
    "\n",
    "\n",
    "### Lasso regression의 강점\n",
    "- Lasso regression은 ridge regression과는 달리 특정 변수의 계수를 0으로 만들어줍니다. 특정 변수의 계수가 0이 아니라는 것은 **lasso regression 모델이 그 변수를 선택**했다고 볼 수 있습니다.\n",
    "- Lasso regression은 모든 변수가 선택되는 것이 아니라는 점에서 **sparse model** (희소모델)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 모델을 적용하기에 앞서 다음과 같은 데이터 전처리를 다시 실시하였습니다.\n",
    "- X에서 가능한 모든 변수를 사용하여, 모델의 성능이 어떻게 나오는지 파악\n",
    "- 제거한 변수: datetime (수치형 변수가 아니며, year/month/hour로 이미 분리됨),casual & registered (타겟변수인 'total'과 함께 움직이는 변수), total (타겟 변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_ridge(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Ridge(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_ridge(data, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': season         -2.645555\n",
       " holiday        -0.197204\n",
       " workingday      3.596301\n",
       " weather       -24.432129\n",
       " temp            2.636598\n",
       " atemp           2.681716\n",
       " humidity       -0.719221\n",
       " windspeed      -0.548247\n",
       " year           86.695930\n",
       " month           8.380873\n",
       " hour            4.355260\n",
       " season_2       22.788212\n",
       " season_3      -11.611360\n",
       " season_4       -0.737016\n",
       " daytime       140.901989\n",
       " hour_1        -23.616680\n",
       " hour_2        -35.267640\n",
       " hour_3        -52.831775\n",
       " hour_4        -60.393102\n",
       " hour_5        -44.729028\n",
       " hour_6          5.701848\n",
       " hour_7         -2.587597\n",
       " hour_8        144.429509\n",
       " hour_9        -19.039814\n",
       " hour_10       -73.722096\n",
       " hour_11       -56.252170\n",
       " hour_12       -14.382937\n",
       " hour_13       -25.100519\n",
       " hour_14       -42.907136\n",
       " hour_15       -43.851104\n",
       " hour_16        19.761338\n",
       " hour_17       173.718836\n",
       " hour_18       130.666843\n",
       " hour_19        20.561495\n",
       " hour_20       -70.392659\n",
       " hour_21        16.873839\n",
       " hour_22       -25.519348\n",
       " hour_23       -67.901620\n",
       " dtype: float64,\n",
       " 'intercept': -174406.4747270075,\n",
       " 'rmse_test': 102.93651244634425,\n",
       " 'rmse_train': 100.40833575463826,\n",
       " 'rsquared_test': 0.67384128712945968,\n",
       " 'rsquared_train': 0.6940101039019364}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_lasso(data, alpha_value):\n",
    "    X = data.drop(['datetime','casual','registered','total'], axis = 1)\n",
    "    Y = data.total\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)\n",
    "    model = Lasso(alpha = alpha_value)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # Make series using selected features and corresponding coefficients\n",
    "    formula = pd.Series(model.coef_, index = list(X.columns.values))\n",
    "    \n",
    "    # Save intercept\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Calculate training RMSE and testing RMSE\n",
    "    Y_pred_train = model.predict(X_train)\n",
    "    Y_pred_test = model.predict(X_test)\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(Y_train, Y_pred_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(Y_test, Y_pred_test))\n",
    "    \n",
    "    # Calculate training R-square and testing R-square\n",
    "    rsquared_train = model.score(X_train, Y_train)\n",
    "    rsquared_test = model.score(X_test, Y_test)\n",
    "    \n",
    "    # Make result dictionary\n",
    "    result={'formula':formula, 'intercept':intercept, 'rmse_train':rmse_train, 'rmse_test':rmse_test,\n",
    "           'rsquared_train':rsquared_train, 'rsquared_test':rsquared_test}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression 학습 및 테스트 (alpha = 0.1)\n",
    "result = train_test_lasso(data, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'formula': season          0.000000\n",
       " holiday        -0.000000\n",
       " workingday      0.000000\n",
       " weather       -20.571110\n",
       " temp            2.280710\n",
       " atemp           2.862928\n",
       " humidity       -0.809783\n",
       " windspeed      -0.513212\n",
       " year           82.409714\n",
       " month           7.261391\n",
       " hour            4.836019\n",
       " season_2       20.540786\n",
       " season_3       -3.580653\n",
       " season_4        0.000000\n",
       " daytime       142.945117\n",
       " hour_1          0.000000\n",
       " hour_2         -0.000000\n",
       " hour_3         -1.237667\n",
       " hour_4         -9.414874\n",
       " hour_5         -0.000000\n",
       " hour_6          7.887671\n",
       " hour_7          0.000000\n",
       " hour_8        144.134592\n",
       " hour_9          0.000000\n",
       " hour_10       -28.640234\n",
       " hour_11       -11.858157\n",
       " hour_12         0.000000\n",
       " hour_13        -0.000000\n",
       " hour_14        -0.485921\n",
       " hour_15        -1.746418\n",
       " hour_16        12.514733\n",
       " hour_17       167.858855\n",
       " hour_18       122.487087\n",
       " hour_19        12.032479\n",
       " hour_20       -30.749180\n",
       " hour_21        11.488489\n",
       " hour_22        -0.000000\n",
       " hour_23       -28.350062\n",
       " dtype: float64,\n",
       " 'intercept': -165808.93872184493,\n",
       " 'rmse_test': 104.51284688268501,\n",
       " 'rmse_train': 102.66948883397774,\n",
       " 'rsquared_test': 0.66377543501123559,\n",
       " 'rsquared_train': 0.6800734018346094}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파악할 부분\n",
    "- Ridge regression과 Lasso regression의 결과와 단순선형회귀모델의 결과를 비교해보세요.\n",
    "- 위의 Ridge regression과 Lasso regression에서 alpha값을 변형해가면서 결과가 달라지는지 살펴보세요."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
