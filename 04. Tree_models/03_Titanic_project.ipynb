{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset\n",
    "다음 모델들의 테스트 성능을 비교해봅시다.\n",
    "1. Logistic regression\n",
    "2. k-nearest neighbor classifier\n",
    "3. naive Bayes classifier\n",
    "4. Decision tree\n",
    "5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "url = 'data/titanic.csv'\n",
    "titanic = pd.read_csv(url, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "6                   0       3   \n",
       "7                   0       1   \n",
       "8                   0       3   \n",
       "9                   1       3   \n",
       "10                  1       2   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "6                                             Moran, Mr. James    male   NaN   \n",
       "7                                      McCarthy, Mr. Timothy J    male  54.0   \n",
       "8                               Palsson, Master. Gosta Leonard    male   2.0   \n",
       "9            Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0   \n",
       "10                         Nasser, Mrs. Nicholas (Adele Achem)  female  14.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "6                0      0            330877   8.4583   NaN        Q  \n",
       "7                0      0             17463  51.8625   E46        S  \n",
       "8                3      1            349909  21.0750   NaN        S  \n",
       "9                0      2            347742  11.1333   NaN        S  \n",
       "10               1      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      int64\n",
       "Pclass        int64\n",
       "Name         object\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Ticket       object\n",
       "Fare        float64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 1 to 891\n",
      "Data columns (total 11 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Name        891 non-null object\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Ticket      891 non-null object\n",
      "Fare        891 non-null float64\n",
      "Cabin       204 non-null object\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 83.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "5      False\n",
       "6       True\n",
       "7      False\n",
       "8      False\n",
       "9      False\n",
       "10     False\n",
       "11     False\n",
       "12     False\n",
       "13     False\n",
       "14     False\n",
       "15     False\n",
       "16     False\n",
       "17     False\n",
       "18      True\n",
       "19     False\n",
       "20      True\n",
       "21     False\n",
       "22     False\n",
       "23     False\n",
       "24     False\n",
       "25     False\n",
       "26     False\n",
       "27      True\n",
       "28     False\n",
       "29      True\n",
       "30      True\n",
       "       ...  \n",
       "862    False\n",
       "863    False\n",
       "864     True\n",
       "865    False\n",
       "866    False\n",
       "867    False\n",
       "868    False\n",
       "869     True\n",
       "870    False\n",
       "871    False\n",
       "872    False\n",
       "873    False\n",
       "874    False\n",
       "875    False\n",
       "876    False\n",
       "877    False\n",
       "878    False\n",
       "879     True\n",
       "880    False\n",
       "881    False\n",
       "882    False\n",
       "883    False\n",
       "884    False\n",
       "885    False\n",
       "886    False\n",
       "887    False\n",
       "888    False\n",
       "889     True\n",
       "890    False\n",
       "891    False\n",
       "Name: Age, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.Age.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in range (0, len(titanic)):\n",
    "    age = titanic.iloc[i].Age\n",
    "    age = 'child' if age < 20 else 'adult' if age >= 20 else 'unknown'\n",
    "    list.append(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'unknown',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'adult',\n",
       " 'child',\n",
       " 'unknown',\n",
       " 'adult',\n",
       " 'adult']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic['Age_modified'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_modified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "PassengerId                                                           \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   \n",
       "2                1      0          PC 17599  71.2833   C85        C   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "\n",
       "            Age_modified  \n",
       "PassengerId               \n",
       "1                  adult  \n",
       "2                  adult  \n",
       "3                  adult  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_child</th>\n",
       "      <th>Age_unknown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Age_adult  Age_child  Age_unknown\n",
       "PassengerId                                   \n",
       "144                  0          1            0\n",
       "103                  1          0            0\n",
       "403                  1          0            0\n",
       "733                  0          0            1\n",
       "309                  1          0            0\n",
       "53                   1          0            0\n",
       "440                  1          0            0\n",
       "48                   0          0            1\n",
       "414                  0          0            1\n",
       "187                  0          0            1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Age_dummies = pd.get_dummies(titanic.Age_modified, prefix = 'Age')\n",
    "Age_dummies.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Embarked_C  Embarked_Q  Embarked_S\n",
       "PassengerId                                    \n",
       "25                    0           0           1\n",
       "174                   0           0           1\n",
       "507                   0           0           1\n",
       "518                   0           1           0\n",
       "888                   0           0           1\n",
       "890                   1           0           0\n",
       "787                   0           0           1\n",
       "246                   0           1           0\n",
       "464                   0           0           1\n",
       "85                    0           0           1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embarked_dummies = pd.get_dummies(titanic.Embarked, prefix = 'Embarked')\n",
    "Embarked_dummies.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Sex_female  Sex_male\n",
       "PassengerId                      \n",
       "743                   1         0\n",
       "336                   0         1\n",
       "601                   1         0\n",
       "781                   1         0\n",
       "194                   0         1\n",
       "858                   0         1\n",
       "747                   0         1\n",
       "871                   0         1\n",
       "727                   1         0\n",
       "740                   0         1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sex_dummies = pd.get_dummies(titanic.Sex, prefix = 'Sex')\n",
    "Sex_dummies.sample (n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([titanic, Age_dummies, Embarked_dummies, Sex_dummies], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_modified</th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_child</th>\n",
       "      <th>Age_unknown</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "PassengerId                                                           \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   \n",
       "2                1      0          PC 17599  71.2833   C85        C   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "4                1      0            113803  53.1000  C123        S   \n",
       "5                0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "            Age_modified  Age_adult  Age_child  Age_unknown  Embarked_C  \\\n",
       "PassengerId                                                               \n",
       "1                  adult          1          0            0           0   \n",
       "2                  adult          1          0            0           1   \n",
       "3                  adult          1          0            0           0   \n",
       "4                  adult          1          0            0           0   \n",
       "5                  adult          1          0            0           0   \n",
       "\n",
       "             Embarked_Q  Embarked_S  Sex_female  Sex_male  \n",
       "PassengerId                                                \n",
       "1                     0           1           0         1  \n",
       "2                     0           0           1         0  \n",
       "3                     0           1           1         0  \n",
       "4                     0           1           1         0  \n",
       "5                     0           1           0         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Name', 'Sex', 'Age', 'Age_modified', 'Ticket', 'Fare', 'Cabin', 'Embarked'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_child</th>\n",
       "      <th>Age_unknown</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  SibSp  Parch  Age_adult  Age_child  \\\n",
       "PassengerId                                                         \n",
       "1                   0       3      1      0          1          0   \n",
       "2                   1       1      1      0          1          0   \n",
       "3                   1       3      0      0          1          0   \n",
       "4                   1       1      1      0          1          0   \n",
       "5                   0       3      0      0          1          0   \n",
       "\n",
       "             Age_unknown  Embarked_C  Embarked_Q  Embarked_S  Sex_female  \\\n",
       "PassengerId                                                                \n",
       "1                      0           0           0           1           0   \n",
       "2                      0           1           0           0           1   \n",
       "3                      0           0           0           1           1   \n",
       "4                      0           0           0           1           1   \n",
       "5                      0           0           0           1           0   \n",
       "\n",
       "             Sex_male  \n",
       "PassengerId            \n",
       "1                   1  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "5                   1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 변수명 가져오기\n",
    "col_names = data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[col_names[1:]]\n",
    "Y = data[col_names[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_adult</th>\n",
       "      <th>Age_child</th>\n",
       "      <th>Age_unknown</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass  SibSp  Parch  Age_adult  Age_child  Age_unknown  \\\n",
       "PassengerId                                                            \n",
       "1                 3      1      0          1          0            0   \n",
       "2                 1      1      0          1          0            0   \n",
       "3                 3      0      0          1          0            0   \n",
       "4                 1      1      0          1          0            0   \n",
       "5                 3      0      0          1          0            0   \n",
       "\n",
       "             Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \n",
       "PassengerId                                                            \n",
       "1                     0           0           1           0         1  \n",
       "2                     1           0           0           1         0  \n",
       "3                     0           0           1           1         0  \n",
       "4                     0           0           1           1         0  \n",
       "5                     0           0           1           0         1  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split data into 3 sets\n",
    "1. Training set (50%)\n",
    "2. Validation set (30%)\n",
    "3. Test set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_val_test_split(X, Y, val_size=0.3, test_size=0.2, random_state=123):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=random_state)\n",
    "    val_size_rev = val_size / (1 - test_size)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train,\n",
    "                                                      test_size=val_size_rev,\n",
    "                                                      random_state=random_state)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, Y_train, Y_val, Y_test = train_val_test_split(X, Y,\n",
    "                                                                      val_size=0.3,\n",
    "                                                                      test_size=0.2,\n",
    "                                                                      random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 11)\n",
      "(267, 11)\n",
      "(179, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fit the model and compare validation AUCs\n",
    "비교하고자 하는 classifiers들은 다음과 같음\n",
    "1. Logistic regression\n",
    "2. k-nearest neighbor classifier\n",
    "3. naive Bayes classifier\n",
    "4. Decision tree\n",
    "5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Logistic regression\n",
    "Manual for `sklearn.linear_model.LogisticRegression`: [click](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "\n",
    "다음 parameter들에 대해 validation data에 대한 AUC값을 살펴볼 것\n",
    "1. penalty\n",
    "2. C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C가 클수록 weak regularization\n",
    "penalty_set = ['l1', 'l2']\n",
    "C_set = [0.1, 1, 10, 1e2, 1e3, 1e4, 1e5, 1e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for penalty in penalty_set:\n",
    "    for C in C_set:\n",
    "        model = LogisticRegression(penalty=penalty, C=C, class_weight='balanced')\n",
    "        model = model.fit(X_train, Y_train)\n",
    "#         Y_val_score = model.decision_function(X_val)\n",
    "        Y_val_score = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(Y_val, Y_val_score)\n",
    "        result.append((model, penalty, C, auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  0.1,\n",
       "  0.80741943241943237),\n",
       " (LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  1,\n",
       "  0.8306878306878307),\n",
       " (LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  10,\n",
       "  0.83285233285233284),\n",
       " (LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  100.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  1000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=10000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  10000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=100000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  100000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  1000000.0,\n",
       "  0.83297258297258303),\n",
       " (LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  0.1,\n",
       "  0.828884078884079),\n",
       " (LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  1,\n",
       "  0.83183020683020692),\n",
       " (LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  10,\n",
       "  0.83297258297258303),\n",
       " (LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  100.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  1000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=10000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  10000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=100000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  100000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  1000000.0,\n",
       "  0.83297258297258303)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_result = sorted(result, key=lambda x: x[3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  100.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  1000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=10000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  10000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=100000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  100000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  100.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  1000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=10000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  10000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=100000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  100000.0,\n",
       "  0.83297258297258314),\n",
       " (LogisticRegression(C=1000000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  1000000.0,\n",
       "  0.83297258297258303),\n",
       " (LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  10,\n",
       "  0.83297258297258303),\n",
       " (LogisticRegression(C=1000000.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  1000000.0,\n",
       "  0.83297258297258303),\n",
       " (LogisticRegression(C=10, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  10,\n",
       "  0.83285233285233284),\n",
       " (LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  1,\n",
       "  0.83183020683020692),\n",
       " (LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  1,\n",
       "  0.8306878306878307),\n",
       " (LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l2',\n",
       "  0.1,\n",
       "  0.828884078884079),\n",
       " (LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'l1',\n",
       "  0.1,\n",
       "  0.80741943241943237)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False), 'l1', 100.0, 0.83297258297258314)\n"
     ]
    }
   ],
   "source": [
    "best_logreg_result = logreg_result[0]\n",
    "print(best_logreg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. k-nearest neighbor classifier\n",
    "Manual for `sklearn.neighbors.KNeighborsClassifier`: [click](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "다음 parameter들에 대해 validation data에 대한 AUC값을 살펴볼 것\n",
    "1. n_neighbors\n",
    "2. weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_set = ['uniform', 'distance']\n",
    "n_neighbors_set = [1, 3, 5, 7, 9, 11, 13, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for weights in weights_set:\n",
    "    for n_neighbors in n_neighbors_set:\n",
    "        model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "        model = model.fit(X_train, Y_train)\n",
    "        Y_val_score = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(Y_val, Y_val_score)\n",
    "        result.append((model, weights, n_neighbors, auc(fpr, tpr)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_result = sorted(result, key=lambda x: x[3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "             weights='uniform'), 'uniform', 7, 0.82822270322270319),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "             weights='uniform'), 'uniform', 9, 0.82187950937950938),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "             weights='uniform'), 'uniform', 15, 0.8201659451659451),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "             weights='uniform'), 'uniform', 5, 0.81752044252044254),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "             weights='uniform'), 'uniform', 13, 0.8174302549302549),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
       "             weights='uniform'), 'uniform', 11, 0.81664862914862912),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "             weights='uniform'), 'uniform', 3, 0.79368085618085626),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "             weights='distance'), 'distance', 7, 0.79154641654641655),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "             weights='distance'), 'distance', 5, 0.78207671957671954),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "             weights='distance'), 'distance', 9, 0.77979196729196731),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "             weights='distance'), 'distance', 15, 0.77194564694564705),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=11, p=2,\n",
       "             weights='distance'), 'distance', 11, 0.77170514670514678),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "             weights='distance'), 'distance', 3, 0.77053270803270801),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=13, p=2,\n",
       "             weights='distance'), 'distance', 13, 0.76809764309764317),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "             weights='uniform'), 'uniform', 1, 0.73187229437229429),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "             weights='distance'), 'distance', 1, 0.73187229437229429)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform'), 'uniform', 7, 0.82822270322270319)\n"
     ]
    }
   ],
   "source": [
    "best_knn_result = knn_result[0]\n",
    "print(best_knn_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. naive Bayes clasifier\n",
    "Manual for `sklearn.naive_bayes.GaussianNB`: [click](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html)\n",
    "\n",
    "클래스에 대한 prior 정보를 조절하여 fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "priors_set = [None, [0.5, 0.5], [0.6, 0.4], [0.7, 0.3], [0.8, 0.2], [0.9, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for priors in priors_set:\n",
    "    model = GaussianNB(priors=priors)\n",
    "    model = model.fit(X_train, Y_train)\n",
    "    Y_val_score = model.predict_proba(X_val)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(Y_val, Y_val_score)\n",
    "    result.append((model, priors, auc(fpr, tpr)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_result = sorted(result, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(GaussianNB(priors=None), None, 0.82070707070707083),\n",
       " (GaussianNB(priors=[0.5, 0.5]), [0.5, 0.5], 0.82070707070707083),\n",
       " (GaussianNB(priors=[0.6, 0.4]), [0.6, 0.4], 0.82070707070707083),\n",
       " (GaussianNB(priors=[0.7, 0.3]), [0.7, 0.3], 0.82070707070707083),\n",
       " (GaussianNB(priors=[0.8, 0.2]), [0.8, 0.2], 0.82070707070707083),\n",
       " (GaussianNB(priors=[0.9, 0.1]), [0.9, 0.1], 0.82070707070707083)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GaussianNB(priors=None), None, 0.82070707070707083)\n"
     ]
    }
   ],
   "source": [
    "best_nb_result = nb_result[0]\n",
    "print(best_nb_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Decision tree\n",
    "Manual for `sklearn.tree.DecisionTreeClassifier`: [click](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "다음 parameter들에 대해 validation data에 대한 AUC값을 살펴볼 것\n",
    "1. max_depth\n",
    "2. class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight_set = [None, 'balanced']\n",
    "max_depth_set = [3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for class_weight in class_weight_set:\n",
    "    for max_depth in max_depth_set:\n",
    "        model = DecisionTreeClassifier(class_weight=class_weight, max_depth=max_depth)\n",
    "        model = model.fit(X_train, Y_train)\n",
    "        Y_val_score = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(Y_val, Y_val_score)\n",
    "        result.append((model, class_weight, max_depth, auc(fpr, tpr)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_result = sorted(result, key=lambda x: x[3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'balanced',\n",
       "  5,\n",
       "  0.83237133237133243),\n",
       " (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  None,\n",
       "  5,\n",
       "  0.82996632996633013),\n",
       " (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  None,\n",
       "  6,\n",
       "  0.82124819624819623),\n",
       " (DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=6,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'balanced',\n",
       "  6,\n",
       "  0.82124819624819623),\n",
       " (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  None,\n",
       "  4,\n",
       "  0.82121813371813379),\n",
       " (DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'balanced',\n",
       "  4,\n",
       "  0.82121813371813379),\n",
       " (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  None,\n",
       "  3,\n",
       "  0.82064694564694562),\n",
       " (DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'balanced',\n",
       "  3,\n",
       "  0.82064694564694562),\n",
       " (DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=7,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  'balanced',\n",
       "  7,\n",
       "  0.8162878787878789),\n",
       " (DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  None,\n",
       "  7,\n",
       "  0.81574675324675316)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'), 'balanced', 5, 0.83237133237133243)\n"
     ]
    }
   ],
   "source": [
    "best_dt_result = dt_result[0]\n",
    "print(best_dt_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Random forest\n",
    "다음 parameter들에 대해 validation data에 대한 AUC값을 살펴볼 것\n",
    "1. n_estimators\n",
    "2. max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators_set = [5, 10, 15, 20]\n",
    "max_features_set = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for n_estimators in n_estimators_set:\n",
    "    for max_features in max_features_set:\n",
    "        model = RandomForestClassifier(n_estimators=n_estimators, max_features=max_features)\n",
    "        model = model.fit(X_train, Y_train)\n",
    "        Y_val_score = model.predict_proba(X_val)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(Y_val, Y_val_score)\n",
    "        result.append((model, n_estimators, max_features, auc(fpr, tpr)))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_result = sorted(result, key=lambda x: x[3], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 15, 'sqrt', 0.81854256854256846),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 20, 'sqrt', 0.8099747474747474),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 20, 'auto', 0.8091029341029341),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 10, 'auto', 0.80904280904280901),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 10, 'sqrt', 0.80814093314093316),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=5, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 5, 'sqrt', 0.80540524290524296),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 15, 'auto', 0.8035113035113034),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 10, 'log2', 0.80303030303030287),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=5, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 5, 'auto', 0.80257936507936511),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 15, 'log2', 0.79969336219336218),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=20, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 20, 'log2', 0.7921777296777297),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=5, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 5, 'log2', 0.78279822029822022)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False), 15, 'sqrt', 0.81854256854256846)\n"
     ]
    }
   ],
   "source": [
    "best_rf_result = rf_result[0]\n",
    "print(best_rf_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
      " KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
      "           weights='uniform'),\n",
      " GaussianNB(priors=None),\n",
      " DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      " RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)]\n"
     ]
    }
   ],
   "source": [
    "selected_models = []\n",
    "selected_models.append(best_logreg_result[0])\n",
    "selected_models.append(best_knn_result[0])\n",
    "selected_models.append(best_nb_result[0])\n",
    "selected_models.append(best_dt_result[0])\n",
    "selected_models.append(best_rf_result[0])\n",
    "pprint(selected_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result = []\n",
    "\n",
    "for model in selected_models:\n",
    "    Y_test_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(Y_test, Y_test_score)\n",
    "    test_result.append((model, auc(fpr, tpr)))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  0.87442645074224024),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "             weights='uniform'), 0.85499325236167356),\n",
       " (GaussianNB(priors=None), 0.83609986504723344),\n",
       " (DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  0.85870445344129565),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 0.84959514170040507)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_result = sorted(test_result, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "            multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "  0.87442645074224024),\n",
       " (DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=5,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              presort=False, random_state=None, splitter='best'),\n",
       "  0.85870445344129565),\n",
       " (KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "             metric_params=None, n_jobs=1, n_neighbors=7, p=2,\n",
       "             weights='uniform'), 0.85499325236167356),\n",
       " (RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "              n_estimators=15, n_jobs=1, oob_score=False, random_state=None,\n",
       "              verbose=0, warm_start=False), 0.84959514170040507),\n",
       " (GaussianNB(priors=None), 0.83609986504723344)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Discussion"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
